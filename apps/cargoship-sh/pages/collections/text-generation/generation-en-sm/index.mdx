import LayoutMdx from "@/components/layout/LayoutMdx";
import ResponsiveEmbed from "react-responsive-embed";
import { Callout } from "@/components/shared/Callout";
import { DiscordCTA } from "@/components/shared/DiscordCTA";
import { TextGenerationEnDemo } from "@/components/models/TextGenerationEnDemo";

export const meta = {
  title: "Generation [English]",
  description: "Automatically generates natural language text by completing a given input text.",
};

```
docker pull cargoshipsh/text-generation-en-sm
```

Automatically generates text by completing a given input text. This is a GPT-2 model provided by HF Canonical Model Maintainers on [Huggingface](https://huggingface.co/gpt2) and was trained on dataset (called WebText) weighting 40 GB of texts but has not been publicly released. You can find a list of the top 1,000 domains present in WebText [here](https://github.com/openai/gpt-2/blob/master/domains.txt). The model itself is 510 MB in size and needs an aditional 1.5MB for the tokenizer. On a moderate CPU it takes only a few seconds to generate a text.

## Demo

<TextGenerationEnDemo />

## License

The model as well as the code for the API wrapper is licensed under [MIT License](https://opensource.org/license/mit/).

## System Requirements

**Minimum**: 2GB RAM, 1 vCPU<br/>
**Recommended**: 4GB RAM, 4 vCPU

## Limitations

The training dataset contains unfiltered internet content which may be profane, lewd or otherwise offensive. Depending on the application, GPT-2 may produce text that is socially unacceptable. When using GPT-2, it is important to remember that the statistically most likely next token is often not the token that produces the most "accurate" text. The output will often not match the input in terms of content, and the sentence structure will often be incorrect.

## Usage

**Input [POST]**

```json
{
  "text": "Hello, I'm a language model"
}
```

**Output**

```json
{
  "text": "Hello, I'm a language modeler. The data coming from the model is the value of the model's function. For example, the values
stored in a table are the first row, the first column from the model, if any, and the"
}
```

You need to set an API Key via the environment variable `API_KEY` to run the image and set the `X-API-KEY` header in your request with the same KEY.

<Callout type="note" title="Need a more detailed setup guide?">
  To get more detailed instructions how to get started please check out our [quick start
  guide](/docs/basics/quickstart) in the docs.
</Callout>

### Example

Make sure you have Docker installed then run the following command:

```bash
docker run -p 80:80 --env API_KEY=CHANGE_ME cargoshipsh/text-generation-en-sm
```

In a new terminal window, run the following command to call the API

```bash
curl -X POST -H 'Content-type: application/json' -H 'X-API-Key: CHANGE_ME' --data '{"text": "Hello, I'm a language model"}' http://localhost:80
```

You see the output of the model in the terminal.

```bash
{"text": "Hello, I'm a language modeler. The data coming from the model is the value of the model's function. For example, the values
stored in a table are the first row, the first column from the model, if any, and the"}
```

<DiscordCTA />

export default ({ children }) => <LayoutMdx meta={meta}>{children}</LayoutMdx>;
